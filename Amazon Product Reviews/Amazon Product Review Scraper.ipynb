{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matthew Grace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon product review webscraper. I am scraping amazon product reviews from customers, and storing as a csv. This will be accomplished using Beautiful Soup (bs4)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Statements and initital setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import statements\n",
    "import requests\n",
    "import bs4\n",
    "import html5lib\n",
    "import pandas\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking that a request to an amazon product page works\n",
    "url = 'https://www.amazon.com/Brazilian-Jiu-Jitsu-Uniform-Preshrunk/dp/B07CZSBLMV/ref=sr_1_4?dchild=1&keywords=mma+gi&qid=1581012491&sr=8-4'\n",
    "header = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:69.0) Gecko/20100101 Firefox/69.0'}\n",
    "test = requests.get(url,headers=header)\n",
    "test.reason"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Request is OK, so I can use Amazon to scrape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Brazilian Jiu Jitsu Gi BJJ Gi for Men & Women Grappling gi Uniform Kimonos Ultra Light, Preshrunk, Free White Belt!!!'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking to make sure beautifulsoup works appropriately \n",
    "soup = bs4.BeautifulSoup(test.text,'html5lib')\n",
    "prod_name = soup.find('span',{'class':\"a-size-large\"})\n",
    "prod_name.text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function returns the link to the product review page for a given product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soupp: bs4 object\n",
    "# n, index of review on page.\n",
    "# if not the last page of reviews, n=9\n",
    "# returns string of customer review for given product (the soupp argument will have\n",
    "# be constructed for a certain product)\n",
    "def get_review(soupp, n):\n",
    "    rev = soupp.find_all('span',{'data-hook':\"review-body\"})\n",
    "    return rev[n].text.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions will use the same arguments as the get_review method, but returns other desired data from the customer review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a string of the date the review was posted\n",
    "def get_review_date(soupp,n):\n",
    "    d = soupp.find_all('span',{'data-hook':\"review-date\"})\n",
    "    return d[n].text[33:] #only date in the html for the page is a string of the form\n",
    "# \"Product reviewed in the United States on *data*\", so indexing is required\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a float of the review's rating\n",
    "def get_review_rating(soupp,n):\n",
    "    r = soupp.find_all('i',{'data-hook':\"review-star-rating\"})\n",
    "    return float(r[n].text.strip().split()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns an integer of the number of reviews, this can be done on any of the review pages\n",
    "def num_reviews(soupp):\n",
    "    ans = int(soupp.find('span',{'data-hook':\"cr-filter-info-review-count\"}).text.split()[-2])    \n",
    "    return ans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns the username of the customer who wrote the review\n",
    "def get_review_author(soupp,n):\n",
    "    a = soupp.find_all('span',{'class':\"a-profile-name\"})\n",
    "    return a[n].text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns the name of the product the review was written for\n",
    "def get_prod_name(soupp):\n",
    "    pn = soupp.find('a',{'data-hook':\"product-link\"})\n",
    "    return pn.text\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I can use all of these helper functions to create a new function that will get the review data in a list of list form, for a particular product page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#soupp: bs4 object to parse\n",
    "#url: the product's url for return purposes\n",
    "#returns a list of lists with each reviews data.\n",
    "def get_review_data_page(soupp, url,n):\n",
    "    out = []\n",
    "    for i in range(0,n):\n",
    "        out.append([get_prod_name(soupp), get_review_rating(soupp,i), get_review_date(soupp,i),\n",
    "                 get_review_author(soupp,i), get_review(soupp,i), url])\n",
    "    return out\n",
    "    \n",
    "            \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have a function for getting all of the review data on a particular page, the next step is to do this for multiple pages of reviews. After failures attempting to do this through the html tags on the review page, I discovered that the url for different products is the same for all amazon products with the exception of the product name, and an indentifier. These can be used along with an increment in the review page counter that can be found in the review url to go through each page of the reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Brazilian-Jiu-Jitsu-Uniform-Preshrunk', 'B07CZSBLMV']\n"
     ]
    }
   ],
   "source": [
    "# url: url of the product's page\n",
    "def strip_id_and_name(url):\n",
    "    id1 = url.find('.com')\n",
    "    id2 = url.find('/dp')\n",
    "    name = url[id1+5:id2]\n",
    "    id3 = url.find('/ref')\n",
    "    id_final = url[id2+4:id3]\n",
    "    return [name,id_final]\n",
    "# testing on an amazon product\n",
    "print(strip_id_and_name('https://www.amazon.com/Brazilian-Jiu-Jitsu-Uniform-Preshrunk/dp/B07CZSBLMV/ref=sr_1_4?dchild=1&keywords=mma+gi&qid=1581012491&sr=8-4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This final function retrieves my desired review data for a given product accross all of it's reviews. There is a noted 2.5 second delay between calls to each review page to ensure that amazon servers do not block my requests, as previous attempts resulted in my connection being blocked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url: url of the product's page\n",
    "# return a list of lists for all review data given a product\n",
    "def get_all_reviews(url): \n",
    "    import time\n",
    "    n_id = strip_id_and_name(url)\n",
    "    name = n_id[0]\n",
    "    prod_id = n_id[1]\n",
    "    \n",
    "    # the reviews url to be manipulated. As previously mentioned the product review\n",
    "    # pages can be parsed with the page number at the end of the url, but given a certain\n",
    "    # product, a name and product id is needed as well, hence the use of the \n",
    "    #strip_id_and_name function\n",
    "    rev_url = 'https://amazon.com/'+name+'/product-reviews/'+prod_id+'/ref=cm_r_arp_d_paging_btm_next_2?ie=UTF8&reviewerType=all_reviews&pageNumber=1'\n",
    "    header = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:69.0) Gecko/20100101 Firefox/69.0'}\n",
    "    start = requests.get(rev_url,headers=header)\n",
    "    soupp = bs4.BeautifulSoup(start.text,'html5lib')\n",
    "    out = []\n",
    "    n_reviews = num_reviews(soupp)\n",
    "    num_pages = int(n_reviews/10)+1\n",
    "    \n",
    "    for i in range(0,num_pages):\n",
    "        n=0\n",
    "        if i==num_pages-1:\n",
    "            n = n_reviews%10\n",
    "        else:\n",
    "            n = 10\n",
    "        \n",
    "        page_data = get_review_data_page(soupp,rev_url, n)        \n",
    "        for x in page_data:\n",
    "            out.append(x)\n",
    "            \n",
    "        next_page = i+2\n",
    "        ind = rev_url.rfind('=')\n",
    "        rev_url = rev_url[:ind+1] + str(next_page)\n",
    "        time.sleep(2.5) # delay to allow requests through\n",
    "        page = requests.get(rev_url,headers=header)\n",
    "\n",
    "        soupp = bs4.BeautifulSoup(page.text,'html5lib')\n",
    "    return out\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all necessary functions created, the list returned with all desired review data will be converted to a dataframe so that it can be saved as a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l: a list, whose contents are also lists. The internal lists have the desired review data\n",
    "def to_df(l):\n",
    "    out = pandas.DataFrame(data=l,columns=['Product Name','Rating','Date','Author','Body','Link'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final block of code is a script I used to run a list of products through my functions, and to save as a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Date</th>\n",
       "      <th>Author</th>\n",
       "      <th>Body</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RHINO RUGBY Fitted Stretch Performance Game Da...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>September 11, 2019</td>\n",
       "      <td>XtinaG</td>\n",
       "      <td>There is great stretch and comfort to these sh...</td>\n",
       "      <td>https://amazon.com/RHINO-RUGBY-Fitted-Stretch-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RHINO RUGBY Fitted Stretch Performance Game Da...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>January 3, 2020</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>Im a medium 31 or 32 waist on every thing i bu...</td>\n",
       "      <td>https://amazon.com/RHINO-RUGBY-Fitted-Stretch-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RHINO RUGBY Fitted Stretch Performance Game Da...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>August 4, 2019</td>\n",
       "      <td>XtinaG</td>\n",
       "      <td>This was my first pair of rugby shorts. I tend...</td>\n",
       "      <td>https://amazon.com/RHINO-RUGBY-Fitted-Stretch-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RHINO RUGBY Fitted Stretch Performance Game Da...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>April 14, 2019</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>I did not want shorts that are tight on the wa...</td>\n",
       "      <td>https://amazon.com/RHINO-RUGBY-Fitted-Stretch-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RHINO RUGBY Fitted Stretch Performance Game Da...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>March 13, 2019</td>\n",
       "      <td>Garrett</td>\n",
       "      <td>Well made, heavy fabric.  The flexible materia...</td>\n",
       "      <td>https://amazon.com/RHINO-RUGBY-Fitted-Stretch-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Product Name  Rating  \\\n",
       "0  RHINO RUGBY Fitted Stretch Performance Game Da...     5.0   \n",
       "1  RHINO RUGBY Fitted Stretch Performance Game Da...     1.0   \n",
       "2  RHINO RUGBY Fitted Stretch Performance Game Da...     5.0   \n",
       "3  RHINO RUGBY Fitted Stretch Performance Game Da...     5.0   \n",
       "4  RHINO RUGBY Fitted Stretch Performance Game Da...     5.0   \n",
       "\n",
       "                 Date           Author  \\\n",
       "0  September 11, 2019           XtinaG   \n",
       "1     January 3, 2020  Amazon Customer   \n",
       "2      August 4, 2019           XtinaG   \n",
       "3      April 14, 2019  Amazon Customer   \n",
       "4      March 13, 2019          Garrett   \n",
       "\n",
       "                                                Body  \\\n",
       "0  There is great stretch and comfort to these sh...   \n",
       "1  Im a medium 31 or 32 waist on every thing i bu...   \n",
       "2  This was my first pair of rugby shorts. I tend...   \n",
       "3  I did not want shorts that are tight on the wa...   \n",
       "4  Well made, heavy fabric.  The flexible materia...   \n",
       "\n",
       "                                                Link  \n",
       "0  https://amazon.com/RHINO-RUGBY-Fitted-Stretch-...  \n",
       "1  https://amazon.com/RHINO-RUGBY-Fitted-Stretch-...  \n",
       "2  https://amazon.com/RHINO-RUGBY-Fitted-Stretch-...  \n",
       "3  https://amazon.com/RHINO-RUGBY-Fitted-Stretch-...  \n",
       "4  https://amazon.com/RHINO-RUGBY-Fitted-Stretch-...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #script to add product dfs to one dataframe and save it\n",
    "\n",
    "urls = ['https://www.amazon.com/RHINO-RUGBY-Fitted-Stretch-Performance/dp/B07QM2J8NX/ref=pd_cp_200_4/130-7457756-6224769?_encoding=UTF8&pd_rd_i=B07QM2J8NX&pd_rd_r=e5b7fc1e-09a5-4e0a-aea0-2185ba8bcd0f&pd_rd_w=6086Q&pd_rd_wg=zTx8n&pf_rd_p=0e5324e1-c848-4872-bbd5-5be6baedf80e&pf_rd_r=3GDN6M2R680300VFQ8ZZ&refRID=3GDN6M2R680300VFQ8ZZ',\n",
    "        'https://www.amazon.com/Nike-Strike-Soccer-White-Racer/dp/B07BT7QPFS/ref=sxin_3_ac_d_pm?ac_md=3-2-QWJvdmUgJDI1-ac_d_pm&keywords=soccer+ball&pd_rd_i=B07BT7QPFS&pd_rd_r=8320be32-68b8-453f-9af2-15a287de225f&pd_rd_w=tSLCD&pd_rd_wg=GQ2Kp&pf_rd_p=24d053a8-30a1-4822-a2ff-4d1ab2b984fc&pf_rd_r=35ACZ9SZKHYRV29CBNK1&psc=1&qid=1571430388&s=sporting-goods',\n",
    "        'https://www.amazon.com/NIKE-Premier-League-Pitch-Soccer/dp/B07DM3XSV5/ref=pd_cp_200_4/130-7457756-6224769?_encoding=UTF8&pd_rd_i=B07DM3XSV5&pd_rd_r=d8198aa7-f84e-4ec7-b6b2-e5f8e9e2cda1&pd_rd_w=yP0jA&pd_rd_wg=hjDqJ&pf_rd_p=0e5324e1-c848-4872-bbd5-5be6baedf80e&pf_rd_r=YA05G2Y2SPS3VK20PBSJ&psc=1&refRID=YA05G2Y2SPS3VK20PBSJ',\n",
    "        'https://www.amazon.com/NIKE-Pitch-Soccer-Ball/dp/B07C2M9GBF/ref=pd_day0_hl_200_5/130-7457756-6224769?_encoding=UTF8&pd_rd_i=B07C2M9GBF&pd_rd_r=ee203f0e-9dd6-471d-803b-e3efa9be5d60&pd_rd_w=gJZJF&pd_rd_wg=yvy8s&pf_rd_p=0501877d-5f8c-4ec8-9861-e0476eecc53e&pf_rd_r=NDFH279PEJVTGA2SAFMZ&refRID=NDFH279PEJVTGA2SAFMZ',\n",
    "        'https://www.amazon.com/Equalizer-Soccer-Shorts-Black-Medium/dp/B00SLSRQYQ/ref=sr_1_12?dchild=1&keywords=soccer+shorts&qid=1571430495&s=sporting-goods&sr=1-12',\n",
    "        'https://www.amazon.com/adidas-Blacks-Rugby-Jersey-Medium/dp/B07KPSDZ9Z/ref=sr_1_4?dchild=1&keywords=rugby+jersey%27&qid=1571430549&s=sporting-goods&sr=1-4',\n",
    "        'https://www.amazon.com/Irish-Rugby-Shirt-Green-Shamrock/dp/B00UY5AX5I/ref=sr_1_3?dchild=1&keywords=rugby+shirt&qid=1571430583&s=sporting-goods&sr=1-3',\n",
    "        'https://www.amazon.com/Guinness-Heritage-Charcoal-Sleeve-Jersey/dp/B07JPXS1ZF/ref=sr_1_2?dchild=1&keywords=rugby+shirt&qid=1571430650&s=sporting-goods&sr=1-2',\n",
    "        'https://www.amazon.com/adidas-Entrada-Jersey-White-Medium/dp/B071GWPKXY/ref=sr_1_5?dchild=1&keywords=soccer+jersey&qid=1571430724&s=sporting-goods&sr=1-5',\n",
    "        'https://www.amazon.com/adidas-Soccer-Madrid-Jersey-Medium/dp/B078H8696L/ref=sr_1_6?dchild=1&keywords=soccer+jersey&qid=1571430764&s=sporting-goods&sr=1-6',\n",
    "        'https://www.amazon.com/adidas-Predator-Ground-Soccer-Metallic/dp/B07KWW74XT/ref=sr_1_3?dchild=1&keywords=soccer+cleats+mens&qid=1571436002&rnid=2941120011&s=apparel&sr=1-3',\n",
    "        'https://www.amazon.com/adidas-Goletto-Ground-Black-Scarlet/dp/B07D9CXNNQ/ref=sr_1_8?dchild=1&keywords=soccer+cleats+mens&qid=1571436002&rnid=2941120011&s=apparel&sr=1-8',\n",
    "        'https://www.amazon.com/adidas-Gloro-Ground-Black-Yellow/dp/B07D9H3Z95/ref=sr_1_9?dchild=1&keywords=soccer+cleats+mens&qid=1571436002&rnid=2941120011&s=apparel&sr=1-9',\n",
    "        'https://www.amazon.com/G-Form-Youth-PRO-S-Compact-Shinguard-Blk-L/dp/B01N9HKXK2/ref=sr_1_29?dchild=1&keywords=shin+guards+soccer&qid=1571436126&s=apparel&sr=8-29',\n",
    "        'https://www.amazon.com/Sportout-Comprehensive-Protection-Cushioned-Injuries/dp/B07JCS6YKB/ref=sr_1_5?dchild=1&keywords=shin+guards+soccer&qid=1571436184&s=apparel&sr=8-5'\n",
    "        ]\n",
    "for i in urls:\n",
    "    reviews = to_df(get_all_reviews(i))\n",
    "    save = pandas.read_csv('amazon_reviews.csv')\n",
    "    save = save.append(reviews)\n",
    "    save.to_csv('amazon_reviews.csv',header=True,index=False)\n",
    "# checking csv\n",
    "pandas.read_csv('amazon_reviews.csv').head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
